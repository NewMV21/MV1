name: Parallel TradingView Scraper

on:
  schedule:
    - cron: '0 0 * * *' # Runs daily at midnight
  workflow_dispatch: # Allows manual trigger

jobs:
  scrape:
    runs-on: ubuntu-latest
    strategy:
      # This creates 5 parallel instances of your script
      matrix:
        shard: [0, 1, 2, 3, 4]
    
    steps:
      - name: Checkout Code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.10'

      - name: Install Dependencies
        run: |
          python -m pip install --upgrade pip
          pip install selenium webdriver-manager beautifulsoup4 gspread google-auth

      - name: Run Scraper Shard
        env:
          GSPREAD_CREDENTIALS: ${{ secrets.GSPREAD_CREDENTIALS }}
          # Logic: 750 symbols / 5 shards = 150 symbols per shard
          # Shard 0: 0-149, Shard 1: 150-299, etc.
          START_INDEX: ${{ matrix.shard * 150 }}
          END_INDEX: ${{ (matrix.shard + 1) * 150 - 1 }}
          CHECKPOINT_FILE: "checkpoint_${{ matrix.shard }}.txt"
        run: python run_scraper.py
